# Portfolio Roadmap: Backend Engineer â†’ Data Engineer

**ëª©í‘œ**: ì‹œë‹ˆì–´ ë°ì´í„° ì—”ì§€ë‹ˆì–´ê°€ ë³´ê³  "ì´ ì‚¬ëŒ ê°™ì´ ì¼í•˜ê³  ì‹¶ë‹¤" ìƒê°í•˜ê²Œ ë§Œë“¤ê¸°

**ê¸°ê°„**: 3ê°œì›” (ì£¼ë§ + í‰ì¼ ì €ë… 2-3ì‹œê°„)

**ì™„ë£Œ ì¡°ê±´**:
- GitHub READMEë¡œ í”„ë¡œì íŠ¸ ì„¤ëª… ê°€ëŠ¥
- ë¼ì´ë¸Œ ë°ëª¨ ê°€ëŠ¥
- ë©´ì ‘ì—ì„œ 30ë¶„ ë™ì•ˆ technical deep-dive ê°€ëŠ¥

---

## ë©´ì ‘ê´€ì´ ë³´ëŠ” ê²ƒ

### âœ… ê¸°ìˆ  ìŠ¤í‚¬
- Streaming ì•„í‚¤í…ì²˜ ì´í•´ë„
- ë°ì´í„° í’ˆì§ˆ ì˜ì‹
- ì„±ëŠ¥ ìµœì í™” ê²½í—˜
- ë¬¸ì œ í•´ê²° ëŠ¥ë ¥

### âœ… ë°ì´í„° ì—”ì§€ë‹ˆì–´ ë§ˆì¸ë“œì…‹
- "ì´ ë°ì´í„°ê°€ ì •í™•í•œê°€?"ì— ëŒ€í•œ ì§‘ì°©
- End-to-end ownership
- í™•ì¥ì„± ê³ ë ¤
- ìš´ì˜ ê²½í—˜

### âœ… í•™ìŠµ ëŠ¥ë ¥
- ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“ ì†ë„
- ë¬¸ì œ ì •ì˜ ë° í•´ê²°
- Trade-off ì´í•´

---

## í˜„ì¬ ìƒíƒœ â†’ ëª©í‘œ ìƒíƒœ

| í•­ëª© | í˜„ì¬ | ëª©í‘œ | ë©´ì ‘ì—ì„œ ë§í•  ìˆ˜ ìˆëŠ” ê²ƒ |
|------|------|------|------------------------|
| **ì•„í‚¤í…ì²˜** | 8/10 | 9/10 | "DDDë¡œ ì„¤ê³„í–ˆê³ , domainì€ Flinkì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" |
| **í…ŒìŠ¤íŠ¸** | 4/10 | 7/10 | "80% ì»¤ë²„ë¦¬ì§€, integration testë¡œ end-to-end ê²€ì¦í•©ë‹ˆë‹¤" |
| **ì„±ëŠ¥** | ?/10 | 8/10 | "ì´ˆë‹¹ 10ë§Œ ì´ë²¤íŠ¸ ì²˜ë¦¬, p99 latency 3ì´ˆ ì´í•˜ì…ë‹ˆë‹¤" |
| **ëª¨ë‹ˆí„°ë§** | 2/10 | 8/10 | "Prometheus + Grafanaë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ì•Œë¦¼ ì„¤ì •í–ˆìŠµë‹ˆë‹¤" |
| **ë°ì´í„° í’ˆì§ˆ** | 5/10 | 8/10 | "Invalid event ë¹„ìœ¨ ì¶”ì , schema validation ì ìš©í–ˆìŠµë‹ˆë‹¤" |
| **ë¬¸ì„œí™”** | 6/10 | 9/10 | "ì•„í‚¤í…ì²˜ ê²°ì •ì„ ADRë¡œ ë¬¸ì„œí™”í–ˆìŠµë‹ˆë‹¤" |

---

## Phase 1: Quick Wins (1ì£¼)

**ëª©í‘œ**: GitHub ì˜¬ë¦¬ê³  ë°”ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” ìƒíƒœ
**ë©´ì ‘ ì§ˆë¬¸ ëŒ€ì‘**: "í”„ë¡œì íŠ¸ ì„¤ëª…í•´ì£¼ì„¸ìš”"

### Task 1.1: README.md ì‘ì„± (3ì‹œê°„)

**ìœ„ì¹˜**: `/README.md`

**ë‚´ìš©**:
```markdown
# Real-time CTR Calculator

Flink ê¸°ë°˜ ì‹¤ì‹œê°„ CTR(Click-Through Rate) ê³„ì‚° íŒŒì´í”„ë¼ì¸

## ğŸ“Š Architecture

[ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€]

Kafka â†’ Flink â†’ ClickHouse

- **Throughput**: ì´ˆë‹¹ 10ë§Œ ì´ë²¤íŠ¸
- **Latency**: p99 < 3ì´ˆ
- **Accuracy**: EXACTLY_ONCE semantics

## ğŸ¯ Why This Project?

ë°±ì—”ë“œ ê°œë°œìì—ì„œ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë¡œ ì „í™˜í•˜ê¸° ìœ„í•œ í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸

**í•µì‹¬ í•™ìŠµ ëª©í‘œ**:
- Streaming ì•„í‚¤í…ì²˜ ì„¤ê³„
- Event time processing & watermarks
- State management
- Data quality engineering

## ğŸ—ï¸ Tech Stack

- **Stream Processing**: Apache Flink 1.18
- **Message Queue**: Kafka (KRaft mode)
- **Storage**: ClickHouse
- **Language**: Kotlin
- **Monitoring**: Prometheus + Grafana
- **Testing**: JUnit 5 + Testcontainers

## ğŸš€ Quick Start

\`\`\`bash
./scripts/setup.sh
\`\`\`

Access:
- Flink UI: http://localhost:8081
- Grafana: http://localhost:3000
- Kafka UI: http://localhost:8080

## ğŸ“ˆ Key Metrics

- Window: 10ì´ˆ tumbling window
- Watermark: 5ì´ˆ out-of-order tolerance
- Parallelism: 2
- Checkpoint: 60ì´ˆ ê°„ê²©

## ğŸ§ª Testing

\`\`\`bash
cd flink-app
./gradlew test
\`\`\`

- **Coverage**: 80%+
- **Integration Tests**: Testcontainersë¡œ end-to-end ê²€ì¦

## ğŸ“š Architecture Decisions

ìƒì„¸í•œ ê¸°ìˆ  ê²°ì •ì€ [docs/ADR](docs/adr/) ì°¸ê³ 

- [ADR-001: Why Kotlin over Java](docs/adr/001-kotlin-migration.md)
- [ADR-002: State Backend Selection](docs/adr/002-state-backend.md)
- [ADR-003: ClickHouse vs Redis](docs/adr/003-storage-choice.md)

## ğŸ”§ What I Learned

1. **Streaming Fundamentals**: Event time vs Processing time ì°¨ì´ë¥¼ ì‹¤ì œë¡œ ê²½í—˜
2. **Data Quality**: Invalid event ì²˜ë¦¬, schema validationì˜ ì¤‘ìš”ì„±
3. **Performance Tuning**: Operator chaining, network buffer ìµœì í™”
4. **Operational Excellence**: Monitoring, alerting, graceful shutdown

## ğŸ“ Contact

ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ [ì´ë©”ì¼] ë˜ëŠ” [LinkedIn]ìœ¼ë¡œ ì—°ë½ì£¼ì„¸ìš”.
```

**ë©´ì ‘ì—ì„œ**: "ì œ GitHubì— READMEê°€ ìˆëŠ”ë°, ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ê³¼ í•¨ê»˜ ì „ì²´ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ë†“ì•˜ìŠµë‹ˆë‹¤"

---

### Task 1.2: ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (2ì‹œê°„)

**ë„êµ¬**: draw.io ë˜ëŠ” Excalidraw

**ë‹¤ì´ì–´ê·¸ë¨ 1: Overall Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Impression â”‚      â”‚    Click    â”‚      â”‚             â”‚
â”‚  Producer   â”‚â”€â”€â”€â”€â”€â–¶â”‚  Producer   â”‚â”€â”€â”€â”€â”€â–¶â”‚    Kafka    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  (3 brokers)â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                           â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                           â”‚    Flink    â”‚
                                           â”‚ JobManager  â”‚
                                           â”‚             â”‚
                                           â”‚ 2 TaskMgrs  â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                         â”‚             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                 â”‚ ClickHouse  â”‚         â”‚   Prometheus    â”‚   â”‚
                 â”‚ (Analytics) â”‚         â”‚   (Metrics)     â”‚   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                                                â”‚
                                                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                                         â”‚   Grafana   â”‚
                                                         â”‚ (Dashboard) â”‚
                                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ë‹¤ì´ì–´ê·¸ë¨ 2: Flink Pipeline**
```
Kafka Source (impressions)  â”€â”
                              â”œâ”€â–¶ Union â”€â–¶ Filter â”€â–¶ KeyBy(productId) â”€â–¶ Window(10s) â”€â–¶ Aggregate â”€â–¶ ClickHouse
Kafka Source (clicks)       â”€â”˜                                             â”‚
                                                                            â””â”€â–¶ Metrics â”€â–¶ Prometheus
```

**ë‹¤ì´ì–´ê·¸ë¨ 3: Data Flow with Timestamps**
```
Event Time: 12:00:00 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
Watermark:  11:59:55 (5s delay) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
                     â”‚         â”‚         â”‚
Window:         [11:59:50, 12:00:00]  [12:00:00, 12:00:10]
                     â”‚                   â”‚
Results:        CTR = 0.45          CTR = 0.52
```

ì´ë¯¸ì§€ë¥¼ `docs/images/` í´ë”ì— ì €ì¥í•˜ê³  READMEì— í¬í•¨

**ë©´ì ‘ì—ì„œ**: "ì•„í‚¤í…ì²˜ëŠ” ì´ë ‡ê²Œ êµ¬ì„±í–ˆëŠ”ë°ìš”, íŠ¹íˆ ì´ ë¶€ë¶„ì´ ì¤‘ìš”í•œ ì´ìœ ëŠ”..."

---

### Task 1.3: í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ ë³µêµ¬ (2ì‹œê°„)

**ì´ìœ **: "í…ŒìŠ¤íŠ¸ ì‘ì„±í–ˆì–´ìš”"ë¼ê³  ë§í•˜ë ¤ë©´ í…ŒìŠ¤íŠ¸ê°€ ëŒì•„ê°€ì•¼ í•¨

**build.gradle.kts ìˆ˜ì •**:
```kotlin
dependencies {
    // ... ê¸°ì¡´ ì˜ì¡´ì„±

    // í…ŒìŠ¤íŠ¸ (ë²„ì „ ëª…ì‹œ)
    testImplementation("org.junit.jupiter:junit-jupiter:5.10.1")
    testImplementation("org.apache.flink:flink-test-utils:$flinkVersion")
    testImplementation("org.assertj:assertj-core:3.24.2")
}

tasks.test {
    useJUnitPlatform()

    maxHeapSize = "1G"

    testLogging {
        events("passed", "skipped", "failed")
        exceptionFormat = org.gradle.api.tasks.testing.logging.TestExceptionFormat.FULL
        showStandardStreams = false
    }
}
```

**ê²€ì¦**:
```bash
cd flink-app
./gradlew clean test

# ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
BUILD SUCCESSFUL in 8s
```

**ë©´ì ‘ì—ì„œ**: "ëª¨ë“  í…ŒìŠ¤íŠ¸ëŠ” CIì—ì„œ ìë™ìœ¼ë¡œ ëŒì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤"

---

### Task 1.4: ê°„ë‹¨í•œ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ (1ì‹œê°„)

**íŒŒì¼**: `scripts/demo.sh`

```bash
#!/bin/bash

echo "=== Real-time CTR Calculator Demo ==="
echo ""

echo "1. Starting infrastructure..."
docker-compose up -d kafka1 kafka2 kafka3 clickhouse

echo ""
echo "2. Waiting for services to be ready..."
sleep 15

echo ""
echo "3. Creating topics..."
./scripts/create-topics.sh

echo ""
echo "4. Starting Flink cluster..."
docker-compose up -d flink-jobmanager flink-taskmanager

sleep 10

echo ""
echo "5. Deploying Flink job..."
./scripts/deploy-flink-job.sh

echo ""
echo "6. Starting data producers..."
./scripts/start-producers.sh

echo ""
echo "=== Demo is running! ==="
echo ""
echo "Access points:"
echo "  - Flink UI: http://localhost:8081"
echo "  - Kafka UI: http://localhost:8080"
echo ""
echo "Checking CTR results in 30 seconds..."
sleep 30

echo ""
echo "Latest CTR results:"
docker-compose exec -T clickhouse clickhouse-client --query \
  "SELECT product_id, impressions, clicks, ctr, window_end
   FROM ctr_results
   ORDER BY window_end DESC
   LIMIT 5
   FORMAT PrettyCompact"

echo ""
echo "=== Demo complete! ==="
echo ""
echo "To stop:"
echo "  ./scripts/stop-all.sh"
```

**ë©´ì ‘ì—ì„œ**: "ë¡œì»¬ì—ì„œ ë°”ë¡œ ë°ëª¨ ëŒë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1ë¶„ì´ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ë™ì‘í•©ë‹ˆë‹¤"

---

### Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] README.md ì‘ì„± (ì•„í‚¤í…ì²˜, ë©”íŠ¸ë¦­, í•™ìŠµ ë‚´ìš©)
- [ ] ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ 3ê°œ ìƒì„±
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥ í™•ì¸
- [ ] ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ë° ê²€ì¦
- [ ] GitHubì— push
- [ ] LinkedInì— í”„ë¡œì íŠ¸ ê³µìœ 

**ì™„ë£Œ ì‹œ ë©´ì ‘ ëŒ€ì‘**:
- âœ… "GitHub ë§í¬ ë³´ë‚´ë“œë¦´ê²Œìš”"
- âœ… "ë¡œì»¬ì—ì„œ ë°”ë¡œ ë°ëª¨ ê°€ëŠ¥í•©ë‹ˆë‹¤"
- âœ… "ì•„í‚¤í…ì²˜ëŠ” ì´ë ‡ê²Œ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤"

---

## Phase 2: Data Engineering Fundamentals (2-3ì£¼)

**ëª©í‘œ**: ë°ì´í„° ì—”ì§€ë‹ˆì–´ë¡œì„œì˜ í•µì‹¬ ì—­ëŸ‰ ì¦ëª…
**ë©´ì ‘ ì§ˆë¬¸ ëŒ€ì‘**: "ë°ì´í„° í’ˆì§ˆì€ ì–´ë–»ê²Œ ë³´ì¥í•˜ë‚˜ìš”?"

### Task 2.1: Data Quality Validation (6ì‹œê°„)

**ìƒˆ íŒŒì¼**: `flink-app/src/main/kotlin/com/example/ctr/domain/service/DataQualityValidator.kt`

```kotlin
class DataQualityValidator(private val metrics: MetricGroup) {

    private val validEvents = metrics.counter("events_valid")
    private val invalidEvents = metrics.counter("events_invalid")
    private val futureTimestamps = metrics.counter("events_future_timestamp")
    private val missingFields = metrics.counter("events_missing_fields")

    fun validate(event: Event): ValidationResult {
        val violations = mutableListOf<String>()

        // Required fields
        if (event.userId.isNullOrBlank()) {
            violations.add("userId is required")
            missingFields.inc()
        }

        if (event.productId.isNullOrBlank()) {
            violations.add("productId is required")
            missingFields.inc()
        }

        if (event.eventType.isNullOrBlank()) {
            violations.add("eventType is required")
            missingFields.inc()
        }

        // Timestamp validation
        event.timestamp?.let { ts ->
            val now = System.currentTimeMillis()
            if (ts > now + 60_000) {  // 1ë¶„ ì´ìƒ ë¯¸ë˜
                violations.add("timestamp is in the future: $ts > $now")
                futureTimestamps.inc()
            }

            if (ts < now - 86_400_000 * 7) {  // 7ì¼ ì´ìƒ ê³¼ê±°
                violations.add("timestamp is too old (> 7 days)")
            }
        }

        // Business rules
        if (event.eventType !in setOf("click", "impression", "view")) {
            violations.add("invalid eventType: ${event.eventType}")
        }

        return if (violations.isEmpty()) {
            validEvents.inc()
            ValidationResult.Valid
        } else {
            invalidEvents.inc()
            ValidationResult.Invalid(violations)
        }
    }
}

sealed class ValidationResult {
    object Valid : ValidationResult()
    data class Invalid(val violations: List<String>) : ValidationResult()
}
```

**EventDeserializationSchemaì— ì ìš©**:
```kotlin
override fun deserialize(message: ByteArray): Event? {
    val event = objectMapper.readValue(message, Event::class.java)

    return when (val result = validator.validate(event)) {
        is ValidationResult.Valid -> event
        is ValidationResult.Invalid -> {
            logger.warn("Invalid event dropped: ${result.violations.joinToString()}")
            null
        }
    }
}
```

**Grafana íŒ¨ë„ ì¶”ê°€**:
- Valid event rate
- Invalid event rate
- Invalid event ìœ í˜•ë³„ ë¶„í¬

**ë©´ì ‘ì—ì„œ**:
- "Invalid eventë¥¼ 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•´ì„œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤"
- "íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë¯¸ë˜ì¸ ê²½ìš°, í•„ìˆ˜ í•„ë“œ ëˆ„ë½, 7ì¼ ì´ìƒ ì˜¤ë˜ëœ ë°ì´í„° ë“±ì„ ê°ì§€í•©ë‹ˆë‹¤"
- "ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ì€ Grafanaì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

---

### Task 2.2: Performance Benchmark (8ì‹œê°„)

**ëª©í‘œ**: "ì´ˆë‹¹ Xê±´ ì²˜ë¦¬ ê°€ëŠ¥"ì´ë¼ê³  ë§í•  ìˆ˜ ìˆê²Œ

#### 2.2.1: Load Generator ì‘ì„±

**íŒŒì¼**: `performance-test/load_generator.py`

```python
#!/usr/bin/env python3
"""
Kafka Load Generator for CTR Pipeline

Usage:
    python load_generator.py --rate 10000 --duration 300
"""

import argparse
import json
import time
from datetime import datetime
from kafka import KafkaProducer
from faker import Faker
import random
import threading
from dataclasses import dataclass

fake = Faker()

@dataclass
class Stats:
    sent: int = 0
    errors: int = 0

    def report(self):
        print(f"Sent: {self.sent:,} | Errors: {self.errors:,} | Rate: {self.sent/60:,.0f}/s")

class LoadGenerator:
    def __init__(self, bootstrap_servers: str, target_rate: int):
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            compression_type='snappy',
            batch_size=16384,
            linger_ms=10
        )
        self.target_rate = target_rate
        self.stats = Stats()
        self.product_ids = [f"product-{i:04d}" for i in range(1000)]

    def generate_event(self, event_type: str) -> dict:
        return {
            "userId": fake.uuid4(),
            "productId": random.choice(self.product_ids),
            "eventType": event_type,
            "timestamp": int(datetime.now().timestamp() * 1000)
        }

    def send_events(self, duration_seconds: int):
        interval = 1.0 / self.target_rate
        end_time = time.time() + duration_seconds

        while time.time() < end_time:
            try:
                # 80% impressions, 20% clicks
                event_type = "impression" if random.random() < 0.8 else "click"
                topic = "impressions" if event_type == "impression" else "clicks"

                event = self.generate_event(event_type)
                self.producer.send(topic, value=event)

                self.stats.sent += 1
                time.sleep(interval)

            except Exception as e:
                self.stats.errors += 1
                print(f"Error: {e}")

        self.producer.flush()

    def run(self, duration_seconds: int):
        print(f"Starting load test: {self.target_rate:,} events/s for {duration_seconds}s")
        print(f"Total events: {self.target_rate * duration_seconds:,}")
        print("-" * 60)

        # Progress reporter
        def report_progress():
            while time.time() < end_time:
                time.sleep(10)
                self.stats.report()

        end_time = time.time() + duration_seconds
        reporter = threading.Thread(target=report_progress)
        reporter.start()

        # Send events
        self.send_events(duration_seconds)
        reporter.join()

        print("-" * 60)
        print(f"Load test complete!")
        self.stats.report()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--bootstrap-servers", default="localhost:9092")
    parser.add_argument("--rate", type=int, required=True, help="Events per second")
    parser.add_argument("--duration", type=int, required=True, help="Duration in seconds")

    args = parser.parse_args()

    generator = LoadGenerator(args.bootstrap_servers, args.rate)
    generator.run(args.duration)
```

#### 2.2.2: Benchmark ì‹¤í–‰

```bash
# 1K events/s
python performance-test/load_generator.py --rate 1000 --duration 300

# 10K events/s
python performance-test/load_generator.py --rate 10000 --duration 300

# 100K events/s (ëª©í‘œ)
python performance-test/load_generator.py --rate 100000 --duration 300
```

#### 2.2.3: ë©”íŠ¸ë¦­ ìˆ˜ì§‘

**ì¸¡ì • í•­ëª©**:
- Input rate (events/s)
- Output rate (records/s)
- End-to-end latency (p50, p95, p99)
- CPU/Memory usage
- Backpressure
- Checkpoint duration

**ê²°ê³¼ ë¬¸ì„œ**: `docs/BENCHMARK_RESULTS.md`

```markdown
# Performance Benchmark Results

## Test Environment

- **Infrastructure**: Docker Compose on MacBook Pro M1
- **Flink**: 1 JobManager, 2 TaskManagers (2 slots each)
- **Kafka**: 3 brokers
- **Parallelism**: 2

## Results

### Throughput Test

| Input Rate | Output Rate | CPU Usage | Memory Usage | Backpressure | Result |
|-----------|-------------|-----------|--------------|--------------|--------|
| 1K/s | 1K/s | 20% | 1.2GB | None | âœ… Pass |
| 10K/s | 10K/s | 45% | 1.8GB | None | âœ… Pass |
| 50K/s | 48K/s | 75% | 2.4GB | Low | âš ï¸ Warning |
| 100K/s | 85K/s | 95% | 3.2GB | High | âŒ Fail |

**Conclusion**: ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•œ throughputì€ **ì´ˆë‹¹ 50K ì´ë²¤íŠ¸**

### Latency Test (10K events/s)

| Metric | Value |
|--------|-------|
| p50 latency | 1.2s |
| p95 latency | 2.8s |
| p99 latency | 4.1s |

**Conclusion**: Window sizeê°€ 10ì´ˆì´ë¯€ë¡œ ì´ë¡ ì  ìµœì†Œ latencyëŠ” 10ì´ˆ. ì‹¤ì œë¡œëŠ” 4ì´ˆ ì´ë‚´ì— ëŒ€ë¶€ë¶„ ì²˜ë¦¬.

### Checkpoint Performance

| Checkpoint Interval | Duration | State Size | Impact |
|--------------------|----------|------------|--------|
| 60s | 3.2s | 45MB | Low |
| 30s | 3.5s | 45MB | Medium |

## Bottleneck Analysis

**CPU-bound**:
- JSON deserializationì´ CPUë¥¼ ë§ì´ ì‚¬ìš©
- ê°œì„  ë°©ì•ˆ: Avro/Protobuf ì‚¬ìš© ì‹œ 30% ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒ

**Memory-bound**:
- Window stateê°€ ë©”ëª¨ë¦¬ ì‚¬ìš©
- ê°œì„  ë°©ì•ˆ: RocksDB state backend ì‚¬ìš© ì‹œ ë” ë§ì€ ìƒíƒœ ì €ì¥ ê°€ëŠ¥

## Optimization Ideas

1. Use Avro instead of JSON (30% faster deserialization)
2. Increase parallelism to 4 (2x throughput)
3. Use RocksDB for state backend (handle larger state)
4. Tune network buffers
```

**ë©´ì ‘ì—ì„œ**:
- "ë¡œì»¬ í™˜ê²½ì—ì„œ ì´ˆë‹¹ 5ë§Œ ê±´ê¹Œì§€ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤"
- "ë³‘ëª©ì€ JSON deserializationì´ì—ˆê³ , Avro ì‚¬ìš© ì‹œ 30% ê°œì„  ê°€ëŠ¥í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤"
- "í”„ë¡œë•ì…˜ì—ì„œëŠ” parallelismì„ ì˜¬ë¦¬ê³  RocksDBë¥¼ ì‚¬ìš©í•˜ë©´ 10ë§Œ ê±´ ì´ìƒ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤"

---

### Task 2.3: Monitoring Dashboard (6ì‹œê°„)

**ëª©í‘œ**: Grafana ëŒ€ì‹œë³´ë“œë¥¼ ë³´ì—¬ì£¼ë©´ì„œ ì„¤ëª…

#### 2.3.1: Prometheus ì„¤ì •

**íŒŒì¼**: `prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'flink'
    static_configs:
      - targets:
          - 'flink-jobmanager:9249'
          - 'flink-taskmanager:9249'
    metrics_path: /metrics
```

**docker-compose.ymlì— ì¶”ê°€**:
```yaml
services:
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    mem_limit: 512m
    cpus: 0.5

  grafana:
    image: grafana/grafana:10.2.2
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    mem_limit: 256m
    cpus: 0.25

volumes:
  prometheus-data:
  grafana-data:
```

#### 2.3.2: Grafana Dashboard

**íŒŒì¼**: `grafana/dashboards/flink-ctr-dashboard.json`

**íŒ¨ë„ êµ¬ì„±**:

1. **Overview Row**
   - Total Events Processed (counter)
   - Current CTR (gauge)
   - Invalid Event Rate (%)
   - Active Products (gauge)

2. **Throughput Row**
   - Events/second (graph)
   - Records out/second (graph)
   - Kafka lag (graph)

3. **Latency Row**
   - End-to-end latency p50/p95/p99 (graph)
   - Window processing time (graph)

4. **Data Quality Row**
   - Valid vs Invalid events (pie chart)
   - Invalid event types (bar chart)
   - Timestamp anomalies (graph)

5. **System Health Row**
   - CPU usage (graph)
   - Memory usage (graph)
   - Checkpoint duration (graph)
   - Backpressure (heatmap)

**ìŠ¤í¬ë¦°ìƒ· ì°ì–´ì„œ READMEì— ì¶”ê°€**

**ë©´ì ‘ì—ì„œ**:
- "ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¡œ ëª¨ë“  ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤"
- (í™”ë©´ ê³µìœ í•˜ë©´ì„œ) "ì—¬ê¸°ì„œ ë°ì´í„° í’ˆì§ˆ, ì²˜ë¦¬ëŸ‰, ë ˆì´í„´ì‹œë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- "Invalid eventê°€ ê°‘ìê¸° ì¦ê°€í•˜ë©´ ì•Œë¦¼ì´ ê°‘ë‹ˆë‹¤"

---

### Task 2.4: Integration Test (8ì‹œê°„)

**ëª©í‘œ**: "End-to-end í…ŒìŠ¤íŠ¸ ì‘ì„±í–ˆìŠµë‹ˆë‹¤"

**íŒŒì¼**: `flink-app/src/test/kotlin/com/example/ctr/integration/CtrPipelineE2ETest.kt`

```kotlin
@Testcontainers
class CtrPipelineE2ETest {

    companion object {
        @Container
        private val kafka = KafkaContainer(
            DockerImageName.parse("confluentinc/cp-kafka:7.4.0")
        ).withKraft()

        @Container
        private val clickhouse = ClickHouseContainer(
            "clickhouse/clickhouse-server:23.8"
        ).withInitScript("init-clickhouse.sql")
    }

    @Test
    fun `should calculate CTR correctly for single product`() {
        // Given: 100 impressions, 25 clicks
        val productId = "test-product-123"
        val baseTime = System.currentTimeMillis()

        val impressions = (1..100).map { i ->
            Event(
                userId = "user-$i",
                productId = productId,
                eventType = "impression",
                timestamp = baseTime + i * 100
            )
        }

        val clicks = (1..25).map { i ->
            Event(
                userId = "user-$i",
                productId = productId,
                eventType = "click",
                timestamp = baseTime + i * 400
            )
        }

        // When: Send to Kafka
        produceEvents(kafka, "impressions", impressions)
        produceEvents(kafka, "clicks", clicks)

        // Run Flink pipeline
        val env = createTestEnvironment()
        val pipeline = buildPipeline(env, kafka, clickhouse)

        val jobClient = env.executeAsync("test-job")

        // Wait for window to close + processing
        Thread.sleep(15000)

        jobClient.cancel().get()

        // Then: Verify CTR in ClickHouse
        val result = queryClickHouse(clickhouse, productId)

        assertThat(result).isNotNull
        assertThat(result.productId).isEqualTo(productId)
        assertThat(result.impressions).isEqualTo(100)
        assertThat(result.clicks).isEqualTo(25)
        assertThat(result.ctr).isEqualTo(0.25)
    }

    @Test
    fun `should handle late events correctly`() {
        // Test with late arrivals within allowed lateness
    }

    @Test
    fun `should drop events outside allowed lateness`() {
        // Test with very late events
    }

    @Test
    fun `should handle multiple products in same window`() {
        // Test with 10 different products
    }
}
```

**ì‹¤í–‰**:
```bash
./gradlew test --tests CtrPipelineE2ETest

# ë˜ëŠ” ëª¨ë“  í…ŒìŠ¤íŠ¸
./gradlew test
```

**Coverage í™•ì¸**:
```bash
./gradlew jacocoTestReport
open flink-app/build/reports/jacoco/test/html/index.html
```

**ë©´ì ‘ì—ì„œ**:
- "Testcontainersë¡œ ì‹¤ì œ Kafkaì™€ ClickHouseë¥¼ ë„ì›Œì„œ end-to-end í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤"
- "Late event ì²˜ë¦¬, ì—¬ëŸ¬ product ë™ì‹œ ì²˜ë¦¬ ë“± ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤"
- "CoverageëŠ” 80% ì´ìƒ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤"

---

### Phase 2 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Data quality validator êµ¬í˜„
- [ ] Invalid event ë©”íŠ¸ë¦­ ì¶”ê°€
- [ ] Load generator ì‘ì„±
- [ ] Performance benchmark ì‹¤í–‰ (1K, 10K, 50K)
- [ ] Benchmark ê²°ê³¼ ë¬¸ì„œí™”
- [ ] Prometheus + Grafana ì„¤ì •
- [ ] Grafana dashboard ìƒì„± (5ê°œ row)
- [ ] Dashboard ìŠ¤í¬ë¦°ìƒ· READMEì— ì¶”ê°€
- [ ] Integration test ì‘ì„± (4+ test cases)
- [ ] Test coverage 80% ë‹¬ì„±

**ì™„ë£Œ ì‹œ ë©´ì ‘ ëŒ€ì‘**:
- âœ… "ë°ì´í„° í’ˆì§ˆì„ 5ê°€ì§€ ì¸¡ë©´ì—ì„œ ê²€ì¦í•©ë‹ˆë‹¤"
- âœ… "ì´ˆë‹¹ 5ë§Œ ê±´ê¹Œì§€ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤"
- âœ… "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œê°€ ìˆìŠµë‹ˆë‹¤"
- âœ… "End-to-end í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦í–ˆìŠµë‹ˆë‹¤"

---

## Phase 3: Production-like Experience (1ê°œì›”)

**ëª©í‘œ**: "í”„ë¡œë•ì…˜ ìš´ì˜ ê²½í—˜"ì„ ì‹œë®¬ë ˆì´ì…˜
**ë©´ì ‘ ì§ˆë¬¸ ëŒ€ì‘**: "ì¥ì•  ëŒ€ì‘ ê²½í—˜ì´ ìˆë‚˜ìš”?"

### Task 3.1: ADR (Architecture Decision Records) ì‘ì„± (4ì‹œê°„)

**ëª©í‘œ**: ê¸°ìˆ ì  ì˜ì‚¬ê²°ì •ì„ ë¬¸ì„œí™” â†’ ë©´ì ‘ì—ì„œ "ì™œ ì´ë ‡ê²Œ í–ˆë‚˜ìš”?"ì— ëŒ€ë‹µ

#### ADR-001: Why Kotlin over Java

**íŒŒì¼**: `docs/adr/001-kotlin-migration.md`

```markdown
# ADR-001: Kotlinìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

## Status
Accepted

## Context
ì´ˆê¸°ì—ëŠ” Javaë¡œ ì‘ì„±í–ˆìœ¼ë‚˜ Kotlinìœ¼ë¡œ ì „í™˜ì„ ê³ ë ¤

**Kotlin ì¥ì **:
- Null safety (NullPointerException ë°©ì§€)
- Data class (ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ ê°ì†Œ)
- Extension functions (DSL ì‘ì„± ìš©ì´)
- Coroutines (ë¹„ë™ê¸° ì²˜ë¦¬)

**ìš°ë ¤ì‚¬í•­**:
- FlinkëŠ” Java ì¤‘ì‹¬ ìƒíƒœê³„
- íŒ€ì´ Kotlinì„ ëª¨ë¥¼ ìˆ˜ ìˆìŒ
- ë””ë²„ê¹… ì‹œ decompiled code í™•ì¸ í•„ìš”

## Decision
Kotlinìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•œë‹¤.

**ì´ìœ **:
1. **íƒ€ì… ì•ˆì „ì„±**: `Event.eventTimeMillisUtc(): Long?` vs `Long` - null ì²˜ë¦¬ ê°•ì œ
2. **ì½”ë“œ ê°„ê²°ì„±**: Data classë¡œ Event, EventCount ë“± 50% ì½”ë“œ ê°ì†Œ
3. **DSL**: PipelineBuilderì—ì„œ extension functionìœ¼ë¡œ ê°€ë…ì„± í–¥ìƒ
4. **í•™ìŠµ ê¸°íšŒ**: ê°œì¸ í”„ë¡œì íŠ¸ì´ë¯€ë¡œ ìƒˆ ê¸°ìˆ  ë„ì… ì ê·¹ ì‹œë„

**Trade-off ìˆ˜ìš©**:
- Flink ë¬¸ì„œëŠ” Java ì˜ˆì œ â†’ Kotlinìœ¼ë¡œ ë³€í™˜í•˜ë©° í•™ìŠµ
- íŒ€ í•™ìŠµ ë¹„ìš© â†’ ë¬¸ì„œí™”ë¡œ ì™„í™”

## Consequences

**ê¸ì •ì **:
- NullPointerException 0ê±´ (ì»´íŒŒì¼ íƒ€ì„ì— ì¡í˜)
- ì½”ë“œ ë¼ì¸ ìˆ˜ 30% ê°ì†Œ
- Pipeline DSL ê°€ë…ì„± í–¥ìƒ

**ë¶€ì •ì **:
- Flink ì˜ˆì œ ë³€í™˜ì— ì´ˆê¸° ì‹œê°„ íˆ¬ì
- IDE ì§€ì›ì´ Javaë³´ë‹¤ ì•½ê°„ ëŠë¦¼

## Lessons Learned
Kotlinì˜ null safetyê°€ streaming ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ íŠ¹íˆ ìœ ìš©í•¨.
ì˜ëª»ëœ timestamp ì²˜ë¦¬ ë“±ì—ì„œ ì»´íŒŒì¼ íƒ€ì„ì— ì˜¤ë¥˜ ë°œê²¬.
```

#### ADR-002: ClickHouse vs Redis

**íŒŒì¼**: `docs/adr/002-storage-choice.md`

```markdown
# ADR-002: ClickHouse ì„ íƒ (Redis ì œê±°)

## Status
Accepted (Replaces Redis)

## Context
ì´ˆê¸°ì—ëŠ” Redisë¥¼ serving layerë¡œ ì‚¬ìš©í–ˆìœ¼ë‚˜ ì œê±°í•˜ê³  ClickHouseë¡œ í†µí•©

**ìš”êµ¬ì‚¬í•­**:
- Real-time query (ìµœì‹  CTR ì¡°íšŒ)
- Historical analysis (ì‹œê°„ëŒ€ë³„ CTR íŠ¸ë Œë“œ)
- Aggregation (ìƒí’ˆë³„, ì¹´í…Œê³ ë¦¬ë³„ CTR)

**Option 1: Redis (ê¸°ì¡´)**
- âœ… Low latency (< 1ms)
- âœ… Simple key-value
- âŒ No historical data
- âŒ Limited aggregation
- âŒ ì¶”ê°€ ì¸í”„ë¼ í•„ìš”

**Option 2: ClickHouse**
- âœ… Columnar storage (ë¹ ë¥¸ aggregation)
- âœ… Historical data ì €ì¥
- âœ… SQL ì¿¼ë¦¬ ê°€ëŠ¥
- âš ï¸ Latency ë†’ìŒ (10-50ms)
- âœ… ë‹¨ì¼ storage

**Option 3: Both**
- âœ… Redis for latest, ClickHouse for history
- âŒ ë³µì¡ë„ ì¦ê°€
- âŒ ë°ì´í„° ë™ê¸°í™” ë¬¸ì œ

## Decision
ClickHouse ë‹¨ì¼ storageë¡œ ê°„ë‹¤.

**ì´ìœ **:
1. **Use case ë¶„ì„**: "ìµœì‹  CTR"ë§Œ í•„ìš”í•œ ê²Œ ì•„ë‹ˆë¼ íŠ¸ë Œë“œ ë¶„ì„ì´ ë” ì¤‘ìš”
2. **Latency trade-off**: 50msëŠ” ëŒ€ì‹œë³´ë“œìš©ìœ¼ë¡œ ì¶©ë¶„
3. **ìš´ì˜ ë‹¨ìˆœí™”**: í•˜ë‚˜ì˜ storageë§Œ ê´€ë¦¬
4. **ë¹„ìš© íš¨ìœ¨**: Redis ì¸í”„ë¼ ë¶ˆí•„ìš”

## Consequences

**ê¸ì •ì **:
- ë‹¨ì¼ ì§„ì‹¤ì˜ ì›ì²œ (Single Source of Truth)
- ë³µì¡í•œ ë¶„ì„ ì¿¼ë¦¬ ê°€ëŠ¥
- Materialized Viewë¡œ ì¶”ê°€ ìµœì í™” ê°€ëŠ¥

**ë¶€ì •ì **:
- Real-time APIëŠ” êµ¬ì¶• ì•ˆ í•¨ (ëŒ€ì‹œë³´ë“œë§Œ ì¡´ì¬)

## Migration
1. Redis sink ì œê±°
2. ClickHouse schema ìµœì í™”
3. Grafanaì—ì„œ ClickHouse ì§ì ‘ ì¿¼ë¦¬

## Lessons Learned
ì´ˆê¸°ì— Redisë¥¼ ì¶”ê°€í•œ ê±´ "real-time"ì´ë¼ëŠ” ë‹¨ì–´ì— ì§‘ì°©í–ˆê¸° ë•Œë¬¸.
ì‹¤ì œ use caseë¥¼ ë¨¼ì € ì •ì˜í–ˆì–´ì•¼ í•¨.
```

#### ADR-003: State Backend Selection

**íŒŒì¼**: `docs/adr/003-state-backend.md`

```markdown
# ADR-003: State Backend Selection

## Status
Accepted (Filesystem for development, RocksDB for production)

## Context
FlinkëŠ” ë‘ ê°€ì§€ state backend ì œê³µ:
- Filesystem (in-memory with async snapshots)
- RocksDB (embedded key-value store)

## Decision
**Development**: Filesystem state backend
**Production**: RocksDB state backend

**ì´ìœ **:

**Filesystem ì¥ì ** (ê°œë°œìš©):
- Setup ê°„ë‹¨
- ë¹ ë¥¸ state access
- ë””ë²„ê¹… ìš©ì´
- ë¡œì»¬ ê°œë°œì— ì¶©ë¶„

**RocksDB ì¥ì ** (í”„ë¡œë•ì…˜ìš©):
- State sizeê°€ ë©”ëª¨ë¦¬ë³´ë‹¤ í´ ìˆ˜ ìˆìŒ
- Incremental checkpoint (ë¹ ë¥¸ checkpoint)
- Out-of-memory ë°©ì§€

**í˜„ì¬ í”„ë¡œì íŠ¸**:
- State size: ~50MB (ì‘ìŒ)
- Filesystemìœ¼ë¡œ ì¶©ë¶„í•˜ì§€ë§Œ, RocksDB ì„¤ì •ë„ ì¤€ë¹„

## Configuration
```yaml
# application.yml
ctr:
  job:
    state-backend: FILESYSTEM  # or ROCKSDB
```

## Future
ìƒí’ˆ ìˆ˜ê°€ 1ë§Œ ê°œ ì´ìƒ, stateê°€ 1GB ì´ìƒì´ë©´ RocksDB ì „í™˜
```

**ë©´ì ‘ì—ì„œ**:
- "ê¸°ìˆ  ê²°ì •ë§ˆë‹¤ ADRì„ ì‘ì„±í•´ì„œ whyë¥¼ ë¬¸ì„œí™”í–ˆìŠµë‹ˆë‹¤"
- "Kotlin ì„ íƒ ì´ìœ ëŠ” íƒ€ì… ì•ˆì „ì„±ê³¼ ì½”ë“œ ê°„ê²°ì„± ë•Œë¬¸ì…ë‹ˆë‹¤"
- "Redisë¥¼ ì œê±°í•œ ì´ìœ ëŠ” ì‹¤ì œ use case ë¶„ì„ ê²°ê³¼ ë¶ˆí•„ìš”í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤"

---

### Task 3.2: Chaos Engineering (ì‹¤í—˜) (6ì‹œê°„)

**ëª©í‘œ**: "ì¥ì•  ìƒí™© ëŒ€ì²˜ ê²½í—˜"

#### ì‹¤í—˜ 1: TaskManager Crash

```bash
# 1. íŒŒì´í”„ë¼ì¸ ì •ìƒ ë™ì‘ í™•ì¸
docker-compose ps

# 2. TaskManager í•˜ë‚˜ ê°•ì œ ì¢…ë£Œ
docker kill flink-taskmanager-1

# 3. ê´€ì°°
# - Flink UIì—ì„œ job restart í™•ì¸
# - Checkpoint recovery í™•ì¸
# - ë°ì´í„° ì†ì‹¤ ì—¬ë¶€ í™•ì¸

# 4. TaskManager ë³µêµ¬
docker-compose up -d flink-taskmanager

# 5. ê²°ê³¼ ë¬¸ì„œí™”
```

**ê²°ê³¼**: `docs/CHAOS_EXPERIMENTS.md`

```markdown
# Chaos Engineering Experiments

## Experiment 1: TaskManager Failure

**Hypothesis**: Jobì´ ìë™ìœ¼ë¡œ restartí•˜ê³  ë§ˆì§€ë§‰ checkpointë¶€í„° ë³µêµ¬

**Procedure**:
1. TaskManager 1ê°œ ê°•ì œ ì¢…ë£Œ
2. 5ë¶„ ëŒ€ê¸°
3. TaskManager ë³µêµ¬

**Results**:
- Job restart: âœ… 30ì´ˆ ë‚´ ìë™ restart
- Checkpoint recovery: âœ… ë§ˆì§€ë§‰ checkpoint(60ì´ˆ ì „)ë¶€í„° ë³µêµ¬
- Data loss: âœ… ì—†ìŒ (Kafka offset ê¸°ë°˜ ì¬ì²˜ë¦¬)
- Recovery time: 45ì´ˆ

**Observations**:
- Restart strategyê°€ ì˜ ë™ì‘í•¨
- EXACTLY_ONCE semantics ë³´ì¥ë¨
- Window í•˜ë‚˜ì¹˜(10ì´ˆ) ë°ì´í„°ë§Œ ì¬ì²˜ë¦¬

**Improvements**:
- Checkpoint intervalì„ 30ì´ˆë¡œ ì¤„ì´ë©´ ë³µêµ¬ ì‹œê°„ ë‹¨ì¶• ê°€ëŠ¥
- í•˜ì§€ë§Œ checkpoint overhead ì¦ê°€ â†’ trade-off
```

#### ì‹¤í—˜ 2: Kafka Broker Down

```bash
# Kafka broker í•˜ë‚˜ ì¢…ë£Œ
docker stop kafka2

# Flinkê°€ ê³„ì† ë™ì‘í•˜ëŠ”ì§€ í™•ì¸ (replication factor 3)
```

#### ì‹¤í—˜ 3: Backpressure ìœ ë°œ

```bash
# ClickHouse ëŠë¦¬ê²Œ ë§Œë“¤ê¸°
docker-compose exec clickhouse sh -c "tc qdisc add dev eth0 root netem delay 1000ms"

# Backpressure ë°œìƒ í™•ì¸
# Flink UIì—ì„œ backpressure monitoring
```

**ë©´ì ‘ì—ì„œ**:
- "ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸í•´ë´¤ìŠµë‹ˆë‹¤"
- "TaskManagerê°€ ì£½ì–´ë„ 45ì´ˆ ì•ˆì— ìë™ ë³µêµ¬ë˜ê³  ë°ì´í„° ì†ì‹¤ì´ ì—†ì—ˆìŠµë‹ˆë‹¤"
- "Backpressure ë°œìƒ ì‹œ upstreamì´ ëŠë ¤ì§€ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤"

---

### Task 3.3: Runbook ì‘ì„± (3ì‹œê°„)

**íŒŒì¼**: `docs/RUNBOOK.md`

```markdown
# CTR Pipeline Runbook

## Quick Links
- Flink UI: http://localhost:8081
- Grafana: http://localhost:3000
- ClickHouse: http://localhost:8123

## Health Checks

### 1. Is the job running?
```bash
curl -s http://localhost:8081/jobs | jq '.jobs[] | select(.status=="RUNNING")'
```

### 2. Is data flowing?
```bash
# ClickHouseì—ì„œ ìµœê·¼ 1ë¶„ ë°ì´í„° í™•ì¸
docker-compose exec -T clickhouse clickhouse-client --query \
  "SELECT count(*) FROM ctr_results WHERE window_end > now() - INTERVAL 1 MINUTE"
```

Expected: > 0

### 3. Are there errors?
```bash
docker-compose logs flink-taskmanager --tail 50 | grep ERROR
```

Expected: No ERRORs

## Common Issues

### Issue: Job is not running

**Symptoms**:
- Flink UI shows no running jobs
- No data in ClickHouse

**Diagnosis**:
```bash
docker-compose ps flink-jobmanager flink-taskmanager
docker-compose logs flink-jobmanager --tail 100
```

**Solution**:
```bash
./scripts/deploy-flink-job.sh
```

### Issue: High backpressure

**Symptoms**:
- Grafana shows backpressure > 50%
- Kafka lag increasing

**Diagnosis**:
```bash
# Check ClickHouse performance
docker-compose exec clickhouse clickhouse-client --query "SHOW PROCESSLIST"

# Check Flink parallelism
curl http://localhost:8081/jobs/{job-id}
```

**Solutions**:
1. Increase ClickHouse resources
2. Increase Flink parallelism
3. Increase batch size

### Issue: High invalid event rate

**Symptoms**:
- Grafana shows > 10% invalid events

**Diagnosis**:
```bash
# Check producer logs
docker-compose logs impression-producer --tail 100
docker-compose logs click-producer --tail 100
```

**Solutions**:
1. Check producer schema
2. Check timestamp generation
3. Review validation logic

## Deployment

### Deploy new version
```bash
# 1. Build
cd flink-app
./gradlew clean shadowJar -x test

# 2. Stop old job (with savepoint)
curl -X PATCH http://localhost:8081/jobs/{job-id}/savepoints \
  -H "Content-Type: application/json" \
  -d '{"target-directory": "/tmp/savepoints"}'

# 3. Deploy new job
./scripts/deploy-flink-job.sh --from-savepoint /tmp/savepoints/{savepoint-id}
```

### Rollback
```bash
# Deploy previous version from savepoint
./scripts/deploy-flink-job.sh --from-savepoint /tmp/savepoints/{previous-savepoint-id}
```

## Monitoring Alerts

### Critical Alerts
- Job down > 5 minutes â†’ Page on-call
- Data loss detected â†’ Page on-call
- Checkpoint failure rate > 10% â†’ Page on-call

### Warning Alerts
- Backpressure > 50% for 10 min â†’ Slack
- Invalid event rate > 10% â†’ Slack
- Kafka lag > 100K â†’ Slack

## Escalation
1. Check runbook
2. Check Grafana
3. Check logs
4. Create incident doc
5. Page senior engineer if can't resolve in 30 min
```

**ë©´ì ‘ì—ì„œ**:
- "ìš´ì˜ ê°€ì´ë“œë¥¼ ì‘ì„±í•´ì„œ ëˆ„êµ¬ë‚˜ ì¥ì•  ëŒ€ì‘í•  ìˆ˜ ìˆê²Œ í–ˆìŠµë‹ˆë‹¤"
- "ì£¼ìš” ì´ìŠˆë³„ë¡œ ì§„ë‹¨ ë°©ë²•ê³¼ í•´ê²° ë°©ë²•ì„ ë¬¸ì„œí™”í–ˆìŠµë‹ˆë‹¤"

---

### Phase 3 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ADR 3ê°œ ì‘ì„± (Kotlin, ClickHouse, State Backend)
- [ ] Chaos experiment 3ê°œ ì‹¤í–‰ ë° ë¬¸ì„œí™”
- [ ] Runbook ì‘ì„± (health checks, common issues, deployment)
- [ ] Troubleshooting ê°€ì´ë“œ
- [ ] Monitoring alert ì„¤ì • (Prometheus rules)

**ì™„ë£Œ ì‹œ ë©´ì ‘ ëŒ€ì‘**:
- âœ… "ê¸°ìˆ  ê²°ì •ì„ ADRë¡œ ë¬¸ì„œí™”í–ˆìŠµë‹ˆë‹¤"
- âœ… "ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í—˜í•´ë´¤ìŠµë‹ˆë‹¤"
- âœ… "ìš´ì˜ ê°€ì´ë“œê°€ ìˆìŠµë‹ˆë‹¤"
- âœ… "ì•Œë¦¼ ì„¤ì •ì´ ë˜ì–´ ìˆìŠµë‹ˆë‹¤"

---

## Phase 4: Portfolio & Demo (1ê°œì›”)

**ëª©í‘œ**: ë©´ì ‘ì—ì„œ ìì‹ ìˆê²Œ ë°œí‘œí•  ìˆ˜ ìˆëŠ” ìë£Œ
**ë©´ì ‘ ì§ˆë¬¸ ëŒ€ì‘**: "í”„ë¡œì íŠ¸ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”" (30ë¶„ ë°œí‘œ)

### Task 4.1: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± (8ì‹œê°„)

**ëª©í‘œ**: LinkedIn/ë¸”ë¡œê·¸ì— ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ê³ í€„ë¦¬í‹° í¬ìŠ¤íŠ¸

**íŒŒì¼**: `docs/BLOG_POST.md`

```markdown
# Real-time CTR Calculator: ë°±ì—”ë“œ ê°œë°œìì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì—¬ì •

## TL;DR
5ë…„ì°¨ ë°±ì—”ë“œ ê°œë°œìê°€ 3ê°œì›” ë™ì•ˆ Flink ê¸°ë°˜ ì‹¤ì‹œê°„ CTR ê³„ì‚° íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ë©° ë°°ìš´ ê²ƒë“¤

**ì£¼ìš” ì„±ê³¼**:
- âš¡ ì´ˆë‹¹ 5ë§Œ ì´ë²¤íŠ¸ ì²˜ë¦¬
- ğŸ“Š 80% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
- ğŸ¯ p99 latency < 4ì´ˆ
- ğŸ›¡ï¸ EXACTLY_ONCE semantics

[GitHub](ë§í¬) | [Live Demo](ë§í¬) | [Slides](ë§í¬)

## ì™œ ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í–ˆë‚˜?

ë°±ì—”ë“œ ê°œë°œìë¡œ 5ë…„ ì¼í•˜ë©´ì„œ í•­ìƒ ê¶ê¸ˆí–ˆìŠµë‹ˆë‹¤:
- "ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ë°±ë§Œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ë§Œë“œë‚˜?"
- "ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ API ì„œë²„ì™€ ë­ê°€ ë‹¤ë¥¸ê°€?"

YouTube, Netflix, Amazonì´ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ì„ ì§ì ‘ ë§Œë“¤ì–´ë³´ê³  ì‹¶ì—ˆìŠµë‹ˆë‹¤.

## ë¬´ì—‡ì„ ë§Œë“¤ì—ˆë‚˜?

**Real-time CTR (Click-Through Rate) Calculator**

ê´‘ê³  impressionê³¼ click ì´ë²¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì•„ì„œ 10ì´ˆ ìœˆë„ìš°ë§ˆë‹¤ CTRì„ ê³„ì‚°í•˜ëŠ” íŒŒì´í”„ë¼ì¸.

```
100 impressions + 25 clicks â†’ CTR = 25%
```

**ì•„í‚¤í…ì²˜**:
```
Kafka â†’ Flink â†’ ClickHouse
         â†“
     Prometheus â†’ Grafana
```

## í•µì‹¬ ë„ì „ ê³¼ì œ

### 1. Event Time vs Processing Time

**ë¬¸ì œ**: ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì´ë²¤íŠ¸ê°€ ìˆœì„œëŒ€ë¡œ ì•ˆ ì˜´

**í•´ê²°**:
- Watermarkë¡œ 5ì´ˆ out-of-order í—ˆìš©
- Allowed latenessë¡œ ì¶”ê°€ 5ì´ˆ ëŒ€ê¸°
- ê·¸ ì´í›„ ë„ì°©í•œ ì´ë²¤íŠ¸ëŠ” drop (ë©”íŠ¸ë¦­ìœ¼ë¡œ ì¶”ì )

**ë°°ìš´ ì **: ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œëŠ” "ì‹œê°„"ì´ ë³µì¡í•˜ë‹¤.
ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ì‹œê°„ vs ì‹œìŠ¤í…œì´ ë°›ì€ ì‹œê°„ì„ êµ¬ë¶„í•´ì•¼ í•œë‹¤.

### 2. Exactly-Once Semantics

**ë¬¸ì œ**: TaskManagerê°€ ì£½ìœ¼ë©´ ë°ì´í„° ì†ì‹¤? ì¤‘ë³µ?

**í•´ê²°**:
- Checkpointë¥¼ 60ì´ˆë§ˆë‹¤ ì €ì¥
- Kafka offsetì„ checkpointì— í¬í•¨
- ì¬ì‹œì‘ ì‹œ ë§ˆì§€ë§‰ checkpointë¶€í„° ì¬ì²˜ë¦¬

**ì‹¤í—˜**: TaskManagerë¥¼ ê°•ì œë¡œ killí•´ë´¤ìŒ
- ê²°ê³¼: 45ì´ˆ ë‚´ ìë™ ë³µêµ¬, ë°ì´í„° ì†ì‹¤ 0

**ë°°ìš´ ì **: Checkpointê°€ "ë°ì´í„°ë² ì´ìŠ¤ì˜ transaction"ê³¼ ë¹„ìŠ·í•œ ì—­í• .

### 3. Data Quality

**ë¬¸ì œ**: Invalid eventê°€ 10% ì´ìƒ ë°œê²¬ë¨

**í•´ê²°**:
- Validationì„ 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
  - Missing fields
  - Future timestamp
  - Old timestamp (> 7 days)
  - Invalid event type
  - Other
- ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- Grafanaì—ì„œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

**ë°°ìš´ ì **: ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì—ì„œëŠ” "ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°"ì´ í•„ìˆ˜.
Silent failureëŠ” ì ˆëŒ€ ì•ˆ ë¨.

### 4. Performance Tuning

**ëª©í‘œ**: ì´ˆë‹¹ 10ë§Œ ì´ë²¤íŠ¸ ì²˜ë¦¬

**ì‹œë„í•œ ê²ƒ**:
1. JSON â†’ Avro (30% ì„±ëŠ¥ í–¥ìƒ)
2. Parallelism 2 â†’ 4 (2ë°° ì²˜ë¦¬ëŸ‰)
3. Network buffer íŠœë‹
4. Operator chaining ìµœì í™”

**ê²°ê³¼**:
- ë¡œì»¬: 5ë§Œ events/s (CPU bound)
- ì˜ˆìƒ í”„ë¡œë•ì…˜: 20ë§Œ events/s (ë” ë§ì€ ë¦¬ì†ŒìŠ¤)

**ë°°ìš´ ì **: Bottleneckì„ ì°¾ëŠ” ê²Œ ì¤‘ìš”.
Profiling â†’ ê°€ì„¤ â†’ ì‹¤í—˜ â†’ ì¸¡ì •

## ë°±ì—”ë“œ vs ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§

| ë°±ì—”ë“œ ê°œë°œ | ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ |
|------------|-----------------|
| Request â†’ Response (ì¦‰ì‹œ) | Event â†’ Processing â†’ Result (ì§€ì—°) |
| ì—ëŸ¬ â†’ 500 ì‘ë‹µ (ì‚¬ìš©ìê°€ ì•Œì•„ì°¨ë¦¼) | ì—ëŸ¬ â†’ ì¡°ìš©íˆ ë°ì´í„° ì†ì‹¤ (ëª¨ë¥¼ ìˆ˜ ìˆìŒ) |
| Stateless (ëŒ€ë¶€ë¶„) | Stateful (í•­ìƒ) |
| Scale up (vertical) | Scale out (horizontal) |
| í…ŒìŠ¤íŠ¸: ê¸°ëŠ¥ ê²€ì¦ | í…ŒìŠ¤íŠ¸: ë°ì´í„° ì •í™•ì„± ê²€ì¦ |

**ê°€ì¥ í° ì°¨ì´**:
ë°±ì—”ë“œëŠ” "ë¹ ë¥¸ ì‘ë‹µ"ì´ ì¤‘ìš”í•˜ì§€ë§Œ,
ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì€ "ì •í™•í•œ ë°ì´í„°"ê°€ ì¤‘ìš”.

## ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ ì´ìœ 

**Flink**:
- Kafka Streamsë³´ë‹¤ ê°•ë ¥í•œ windowing
- Spark Streamingë³´ë‹¤ ë‚®ì€ latency
- í’ë¶€í•œ state management

**Kotlin**:
- Null safety â†’ NullPointerException 0ê±´
- Data class â†’ 50% ì½”ë“œ ê°ì†Œ
- Extension function â†’ DSL ì‘ì„± ìš©ì´

**ClickHouse**:
- Columnar storage â†’ ë¹ ë¥¸ aggregation
- SQL ì¿¼ë¦¬ ê°€ëŠ¥
- Time-series ë°ì´í„°ì— ìµœì í™”

**Testcontainers**:
- ì‹¤ì œ Kafka/ClickHouseë¡œ í…ŒìŠ¤íŠ¸
- í†µí•© í…ŒìŠ¤íŠ¸ ì‹ ë¢°ë„ ë†’ìŒ

## ë§Œì•½ ë‹¤ì‹œ í•œë‹¤ë©´?

### ì˜í•œ ê²ƒ
âœ… í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‘ì„± (TDD)
âœ… ë©”íŠ¸ë¦­ ì´ˆê¸°ë¶€í„° ì¶”ê°€
âœ… ADRë¡œ ì˜ì‚¬ê²°ì • ë¬¸ì„œí™”

### ì•„ì‰¬ìš´ ê²ƒ
âŒ ì´ˆê¸°ì— Redisë¥¼ ë„ˆë¬´ ë¹¨ë¦¬ ì¶”ê°€ (ë‚˜ì¤‘ì— ì œê±°)
âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ë‚˜ì¤‘ì— í•¨ (ì´ˆê¸°ë¶€í„° í–ˆì–´ì•¼)
âŒ Schema ë³€ê²½ì„ ê³ ë ¤ ì•ˆ í•¨ (Avro ì²˜ìŒë¶€í„° ì“¸ê±¸)

## ë‹¤ìŒ ë‹¨ê³„

1. **Kubernetes ë°°í¬**: Helm chart ì‘ì„±, HPA ì„¤ì •
2. **Schema Registry**: Avro schema evolution
3. **Data Quality Framework**: Great Expectations í†µí•©
4. **ML Integration**: CTR prediction model ì¶”ê°€

## ë§ˆë¬´ë¦¬

3ê°œì›” ë™ì•ˆ ì´ í”„ë¡œì íŠ¸ë¥¼ í•˜ë©´ì„œ:
- Streaming ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í–ˆìŠµë‹ˆë‹¤
- ë°ì´í„° í’ˆì§ˆì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤
- ë¶„ì‚° ì‹œìŠ¤í…œì˜ ë³µì¡í•¨ì„ ê²½í—˜í–ˆìŠµë‹ˆë‹¤

**ê°€ì¥ í° ë°°ì›€**:
"ë™ì‘í•˜ëŠ” ì½”ë“œ"ì™€ "í”„ë¡œë•ì…˜ ê°€ëŠ¥í•œ ì½”ë“œ"ëŠ” ë‹¤ë¥´ë‹¤.

---

**GitHub**: [ë§í¬]
**LinkedIn**: [ë§í¬]
**Contact**: [ì´ë©”ì¼]
```

**LinkedInì— í¬ìŠ¤íŒ… + ë¸”ë¡œê·¸ ì—…ë¡œë“œ**

**ë©´ì ‘ì—ì„œ**:
- "ì œ ë¸”ë¡œê·¸ì— í”„ë¡œì íŠ¸ ì „ì²´ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤"
- "3ê°œì›” ë™ì•ˆ ë°°ìš´ ê±¸ ì •ë¦¬í–ˆëŠ”ë°, ì½ì–´ë³´ì‹œê² ì–´ìš”?"

---

### Task 4.2: Presentation Deck (6ì‹œê°„)

**ëª©í‘œ**: 30ë¶„ ë°œí‘œ ìë£Œ

**íŒŒì¼**: `docs/presentation.pdf` (Google Slides â†’ PDF)

**ìŠ¬ë¼ì´ë“œ êµ¬ì„±** (25ì¥):

1. **Title** (1ì¥)
   - Real-time CTR Calculator
   - ë¶€ì œ: Backend Engineer â†’ Data Engineer Journey

2. **About Me** (1ì¥)
   - 5ë…„ì°¨ ë°±ì—”ë“œ ê°œë°œì
   - Spring Boot, Kubernetes ê²½í—˜
   - ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì „í™˜ ì¤‘

3. **Problem Statement** (2ì¥)
   - ê´‘ê³  í”Œë«í¼ì—ì„œ CTRì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œì•„ì•¼ í•˜ëŠ” ì´ìœ 
   - ìš”êµ¬ì‚¬í•­: 10ì´ˆ ì´ë‚´ latency, ì´ˆë‹¹ 10ë§Œ ì´ë²¤íŠ¸

4. **Architecture** (3ì¥)
   - Overall architecture diagram
   - Flink pipeline diagram
   - Data flow with timestamps

5. **Key Technical Challenges** (8ì¥)
   - Event time processing (2ì¥)
   - Exactly-once semantics (2ì¥)
   - Data quality (2ì¥)
   - Performance (2ì¥)

6. **Implementation Highlights** (5ì¥)
   - DDD architecture
   - Kotlin ì¥ì 
   - Testing strategy
   - Monitoring

7. **Results** (3ì¥)
   - Performance benchmark ê²°ê³¼
   - Test coverage
   - Demo ìŠ¤í¬ë¦°ìƒ·

8. **Lessons Learned** (2ì¥)
   - Backend vs Data Engineering ì°¨ì´
   - ë‹¤ì‹œ í•œë‹¤ë©´?

9. **Q&A** (1ì¥)

**ë©´ì ‘ì—ì„œ**:
- "ë°œí‘œ ìë£Œë¥¼ ì¤€ë¹„í–ˆëŠ”ë° ë³´ì—¬ë“œë¦´ê¹Œìš”?"
- (í™”ë©´ ê³µìœ ) "ì „ì²´ ì•„í‚¤í…ì²˜ëŠ” ì´ë ‡ìŠµë‹ˆë‹¤..."

---

### Task 4.3: Video Demo (4ì‹œê°„)

**ëª©í‘œ**: 5ë¶„ì§œë¦¬ ë°ëª¨ ì˜ìƒ

**ìŠ¤í¬ë¦½íŠ¸**:

```
[0:00-0:30] Intro
ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ ì œê°€ ë§Œë“  ì‹¤ì‹œê°„ CTR ê³„ì‚° íŒŒì´í”„ë¼ì¸ì„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

[0:30-1:00] Architecture
ì „ì²´ ì•„í‚¤í…ì²˜ëŠ” ì´ë ‡ìŠµë‹ˆë‹¤.
Kafkaì—ì„œ ì´ë²¤íŠ¸ë¥¼ ë°›ì•„ Flinkë¡œ ì²˜ë¦¬í•˜ê³  ClickHouseì— ì €ì¥í•©ë‹ˆë‹¤.

[1:00-2:00] Live Demo - Starting
ì´ì œ ì‹¤ì œë¡œ ëŒë ¤ë³´ê² ìŠµë‹ˆë‹¤.
(í„°ë¯¸ë„) ./scripts/demo.sh
ëª‡ ì´ˆë§Œ ê¸°ë‹¤ë¦¬ë©´... ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì‹œì‘ë©ë‹ˆë‹¤.

[2:00-3:00] Flink UI
Flink UIì—ì„œ jobì´ ì‹¤í–‰ì¤‘ì…ë‹ˆë‹¤.
ì—¬ê¸°ì„œ ê° operatorì˜ throughputì„ ë³¼ ìˆ˜ ìˆê³ ,
backpressureë„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[3:00-4:00] Grafana
Grafana ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.
ì´ˆë‹¹ 1ë§Œ ê°œì˜ ì´ë²¤íŠ¸ê°€ ì²˜ë¦¬ë˜ê³  ìˆê³ ,
p99 latencyëŠ” 3ì´ˆì…ë‹ˆë‹¤.
Invalid event rateëŠ” 1% ë¯¸ë§Œìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.

[4:00-4:30] ClickHouse Results
ClickHouseì—ì„œ ì‹¤ì œ ê²°ê³¼ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤.
10ì´ˆë§ˆë‹¤ CTRì´ ê³„ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤.
Product AëŠ” CTRì´ 25%, Product BëŠ” 15%ë„¤ìš”.

[4:30-5:00] Wrap up
ì´ë ‡ê²Œ ì‹¤ì‹œê°„ìœ¼ë¡œ CTRì„ ê³„ì‚°í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ GitHubì´ë‚˜ LinkedInìœ¼ë¡œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
ê°ì‚¬í•©ë‹ˆë‹¤!
```

**ì´¬ì˜**:
- Screen recording (QuickTime/OBS)
- ëª©ì†Œë¦¬ ë…¹ìŒ
- ìë§‰ ì¶”ê°€ (ì„ íƒ)

**ì—…ë¡œë“œ**:
- YouTube (unlisted)
- READMEì— ë§í¬ ì¶”ê°€

**ë©´ì ‘ì—ì„œ**:
- "5ë¶„ì§œë¦¬ ë°ëª¨ ì˜ìƒì´ ìˆëŠ”ë° ë³´ì—¬ë“œë¦´ê¹Œìš”?"
- ë˜ëŠ” "ë¼ì´ë¸Œë¡œ ë°ëª¨ ë³´ì—¬ë“œë¦´ê¹Œìš”?"

---

### Task 4.4: LinkedIn Profile ì—…ë°ì´íŠ¸ (1ì‹œê°„)

**Projects ì„¹ì…˜ì— ì¶”ê°€**:

```
Real-time CTR Calculator
Jan 2025 - Mar 2025

Apache Flink ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸

â€¢ ì´ˆë‹¹ 5ë§Œ ì´ë²¤íŠ¸ ì²˜ë¦¬ (p99 latency < 4ì´ˆ)
â€¢ EXACTLY_ONCE semanticsë¡œ ë°ì´í„° ì •í™•ì„± ë³´ì¥
â€¢ 80% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë‹¬ì„± (Testcontainersë¡œ end-to-end ê²€ì¦)
â€¢ Prometheus + Grafanaë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
â€¢ Kotlin, Kafka, ClickHouse ì‚¬ìš©
â€¢ DDD ì•„í‚¤í…ì²˜ ì ìš©

Skills: Apache Flink Â· Kafka Â· ClickHouse Â· Kotlin Â· Data Engineering Â·
        Stream Processing Â· Prometheus Â· Grafana

[GitHub] [Demo Video] [Blog Post]
```

**Skills ì„¹ì…˜ì— ì¶”ê°€**:
- Apache Flink
- Stream Processing
- Data Engineering
- Kafka
- ClickHouse

**ë©´ì ‘ì—ì„œ**:
- "LinkedIn í”„ë¡œí•„ì— í”„ë¡œì íŠ¸ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤"

---

### Phase 4 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± (3000ì+)
- [ ] LinkedIn/Mediumì— í¬ìŠ¤íŒ…
- [ ] Presentation deck ì‘ì„± (25ì¥)
- [ ] 5ë¶„ ë°ëª¨ ì˜ìƒ ì´¬ì˜ ë° ì—…ë¡œë“œ
- [ ] GitHub README ìµœì¢… ì—…ë°ì´íŠ¸
- [ ] LinkedIn profile ì—…ë°ì´íŠ¸
- [ ] ë©´ì ‘ ìŠ¤í¬ë¦½íŠ¸ ì—°ìŠµ

**ì™„ë£Œ ì‹œ**:
- âœ… í¬íŠ¸í´ë¦¬ì˜¤ ì™„ì„±
- âœ… ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ
- âœ… 30ë¶„ ë°œí‘œ ê°€ëŠ¥
- âœ… ì˜¨ë¼ì¸ í”„ë ˆì  ìŠ¤ êµ¬ì¶•

---

## ì „ì²´ íƒ€ì„ë¼ì¸

| Phase | ê¸°ê°„ | ëˆ„ì  | ì™„ë£Œ ì¡°ê±´ |
|-------|------|------|-----------|
| Phase 1: Quick Wins | 1ì£¼ | 1ì£¼ | GitHubì— ì˜¬ë¦´ ìˆ˜ ìˆìŒ |
| Phase 2: Fundamentals | 2-3ì£¼ | 4ì£¼ | ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ìŠ¤í‚¬ ì¦ëª… |
| Phase 3: Production-like | 1ê°œì›” | 8ì£¼ | ìš´ì˜ ê²½í—˜ ì‹œë®¬ë ˆì´ì…˜ |
| Phase 4: Portfolio | 1ê°œì›” | 12ì£¼ | ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ |

**Total: 3ê°œì›”**

---

## ë©´ì ‘ ì¤€ë¹„

### ì˜ˆìƒ ì§ˆë¬¸ê³¼ ë‹µë³€

#### Q: "í”„ë¡œì íŠ¸ë¥¼ 30ì´ˆë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”"

**A**:
"Flink ê¸°ë°˜ ì‹¤ì‹œê°„ CTR ê³„ì‚° íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
Kafkaì—ì„œ impression/click ì´ë²¤íŠ¸ë¥¼ ë°›ì•„ 10ì´ˆ ìœˆë„ìš°ë§ˆë‹¤ CTRì„ ê³„ì‚°í•˜ê³  ClickHouseì— ì €ì¥í•©ë‹ˆë‹¤.
ì´ˆë‹¹ 5ë§Œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³ , EXACTLY_ONCE semanticsë¡œ ì •í™•ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
ë°±ì—”ë“œ ê°œë°œìì—ì„œ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë¡œ ì „í™˜í•˜ê¸° ìœ„í•œ í•™ìŠµ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤."

---

#### Q: "ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€?"

**A**:
"Event time processingì´ ê°€ì¥ ì–´ë ¤ì› ìŠµë‹ˆë‹¤.
ì²˜ìŒì—ëŠ” processing timeì„ ì¼ëŠ”ë°, ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì´ë²¤íŠ¸ê°€ ìˆœì„œëŒ€ë¡œ ì•ˆ ì˜¤ë‹ˆ CTRì´ í‹€ë ¸ìŠµë‹ˆë‹¤.
Event timeìœ¼ë¡œ ë°”ê¾¸ê³  watermarkë¥¼ ì¶”ê°€í–ˆëŠ”ë°, out-of-orderë¥¼ ì–¼ë§ˆë‚˜ í—ˆìš©í• ì§€ íŠœë‹í•˜ëŠ” ê²Œ ì–´ë ¤ì› ìŠµë‹ˆë‹¤.
ê²°êµ­ 5ì´ˆë¡œ ì„¤ì •í–ˆê³ , late eventëŠ” ë©”íŠ¸ë¦­ìœ¼ë¡œ ì¶”ì í•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.

ì´ ê³¼ì •ì—ì„œ 'ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ì‹œê°„ì€ ë³µì¡í•˜ë‹¤'ëŠ” ê±¸ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤."

---

#### Q: "ë°ì´í„° ì •í™•ì„±ì€ ì–´ë–»ê²Œ ë³´ì¥í•˜ë‚˜ìš”?"

**A**:
"ì„¸ ê°€ì§€ ë ˆë²¨ì—ì„œ ë³´ì¥í•©ë‹ˆë‹¤:

1. **Message level**: EXACTLY_ONCE semanticsë¡œ ì¤‘ë³µ/ì†ì‹¤ ë°©ì§€
2. **Event level**: Validationìœ¼ë¡œ invalid eventë¥¼ 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ê³  ë©”íŠ¸ë¦­ ìˆ˜ì§‘
3. **Window level**: Integration testë¡œ CTR ê³„ì‚° ë¡œì§ ê²€ì¦

ì¶”ê°€ë¡œ ClickHouseì— ì €ì¥ í›„ reconciliation checkë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Kafka topicì˜ event ìˆ˜ì™€ ClickHouseì˜ row ìˆ˜ë¥¼ ë¹„êµí•˜ëŠ” ë°°ì¹˜ jobì„ ë§Œë“¤ë©´ ë©ë‹ˆë‹¤."

---

#### Q: "ì„±ëŠ¥ì„ ì–´ë–»ê²Œ ìµœì í™”í–ˆë‚˜ìš”?"

**A**:
"Profilingìœ¼ë¡œ bottleneckì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.

**ë°œê²¬**: JSON deserializationì´ CPUì˜ 40% ì‚¬ìš©
**í•´ê²°**: Avroë¡œ ë°”ê¾¸ë‹ˆ 30% ì„±ëŠ¥ í–¥ìƒ

**ë°œê²¬**: Single TaskManagerë¡œ ë³‘ëª©
**í•´ê²°**: Parallelismì„ 2ë¡œ ì˜¬ë¦¬ë‹ˆ ì²˜ë¦¬ëŸ‰ 2ë°°

**ë°œê²¬**: ClickHouse writeê°€ ëŠë¦¼
**í•´ê²°**: Batch sizeë¥¼ 1000ìœ¼ë¡œ ì˜¬ë¦¬ê³  intervalì„ 200msë¡œ

ê²°ê³¼ì ìœ¼ë¡œ ì´ˆë‹¹ 5ë§Œ ì´ë²¤íŠ¸ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤."

---

#### Q: "í”„ë¡œë•ì…˜ì— ë°°í¬í•œë‹¤ë©´?"

**A**:
"ëª‡ ê°€ì§€ë¥¼ ë” ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

1. **Security**: Kafka SASL ì¸ì¦, ClickHouse ì•”í˜¸í™”
2. **Scalability**: Kubernetes HPAë¡œ auto-scaling
3. **State Backend**: RocksDBë¡œ ë³€ê²½ (ë” í° state ì²˜ë¦¬)
4. **Monitoring**: PagerDuty ì—°ë™, runbook ì‘ì„±
5. **Schema Evolution**: Schema Registryë¡œ ë²„ì „ ê´€ë¦¬

ê°€ì¥ ì¤‘ìš”í•œ ê±´ **Chaos Engineering**ì…ë‹ˆë‹¤.
ì‹¤ì œë¡œ ì¥ì• ë¥¼ ì¼ìœ¼ì¼œë³´ê³  ë³µêµ¬ ì‹œê°„ì„ ì¸¡ì •í•´ì•¼ í•©ë‹ˆë‹¤."

---

#### Q: "ë°±ì—”ë“œì™€ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì˜ ì°¨ì´ëŠ”?"

**A**:
"ê°€ì¥ í° ì°¨ì´ëŠ” **í”¼ë“œë°± ì†ë„**ì…ë‹ˆë‹¤.

ë°±ì—”ë“œëŠ”:
- ë²„ê·¸ â†’ 500 ì—ëŸ¬ â†’ ì¦‰ì‹œ ë°œê²¬
- ì„±ëŠ¥ ë¬¸ì œ â†’ ì‘ë‹µ ëŠë¦¼ â†’ ì¦‰ì‹œ ë°œê²¬

ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì€:
- ë²„ê·¸ â†’ ì¡°ìš©íˆ ë°ì´í„° ì†ì‹¤ â†’ ëª‡ ì£¼ í›„ ë°œê²¬
- ì„±ëŠ¥ ë¬¸ì œ â†’ backpressure â†’ lag ìŒ“ì„

ê·¸ë˜ì„œ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì€:
- ë” **ë°©ì–´ì ì¸ í”„ë¡œê·¸ë˜ë°** í•„ìš”
- ë” **ì² ì €í•œ í…ŒìŠ¤íŠ¸** í•„ìš”
- ë” **ì„¸ë°€í•œ ëª¨ë‹ˆí„°ë§** í•„ìš”

ì´ í”„ë¡œì íŠ¸ë¥¼ í•˜ë©´ì„œ 'ë°ì´í„° í’ˆì§ˆì— í¸ì§‘ì¦ì ìœ¼ë¡œ ì§‘ì°©'í•´ì•¼ í•œë‹¤ëŠ” ê±¸ ë°°ì› ìŠµë‹ˆë‹¤."

---

## ì„±ê³µ ê¸°ì¤€

### ê¸°ìˆ ì  ì„±ê³µ
- âœ… GitHub stars > 10
- âœ… ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ views > 100
- âœ… Demo ê°€ëŠ¥
- âœ… 30ë¶„ ë°œí‘œ ê°€ëŠ¥

### ì»¤ë¦¬ì–´ ì„±ê³µ
- âœ… ë°ì´í„° ì—”ì§€ë‹ˆì–´ ë©´ì ‘ í†µê³¼
- âœ… "ì´ ì‚¬ëŒ ê´œì°®ì€ë°?" í‰ê°€ ë°›ìŒ
- âœ… ì˜¤í¼ ë°›ìŒ

### í•™ìŠµ ì„±ê³µ
- âœ… Streaming ì•„í‚¤í…ì²˜ ì´í•´
- âœ… Flink ìì‹ ê°
- âœ… ë°ì´í„° ì—”ì§€ë‹ˆì–´ ë§ˆì¸ë“œì…‹ íšë“

---

## ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ê¸°

### Week 1: Quick Wins
```bash
# Day 1-2: README
- ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ê·¸ë¦¬ê¸°
- README.md ì‘ì„±

# Day 3-4: í…ŒìŠ¤íŠ¸ ê³ ì¹˜ê¸°
cd flink-app
./gradlew clean test

# Day 5-7: ë°ëª¨ ì¤€ë¹„
./scripts/demo.sh ì™„ì„±
```

### Week 2-4: Fundamentals
```bash
# Week 2: Data Quality
- Validator êµ¬í˜„
- ë©”íŠ¸ë¦­ ì¶”ê°€

# Week 3: Performance
- Load generator ì‘ì„±
- Benchmark ì‹¤í–‰

# Week 4: Monitoring
- Grafana dashboard
- Integration test
```

### Week 5-8: Production-like
```bash
# Week 5-6: ADR + Chaos
- ADR 3ê°œ ì‘ì„±
- Chaos experiments

# Week 7-8: Runbook
- ìš´ì˜ ê°€ì´ë“œ
- Troubleshooting
```

### Week 9-12: Portfolio
```bash
# Week 9-10: ë¸”ë¡œê·¸
- í¬ìŠ¤íŠ¸ ì‘ì„±
- LinkedIn ê³µìœ 

# Week 11: Presentation
- Slides ì‘ì„±
- ë°œí‘œ ì—°ìŠµ

# Week 12: Demo
- ì˜ìƒ ì´¬ì˜
- ìµœì¢… ì •ë¦¬
```

---

**ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!**

ì²« ë²ˆì§¸ Task:
```bash
# README.mdì— ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì¶”ê°€í•˜ê¸°
open https://excalidraw.com
```

**3ê°œì›” í›„, ë‹¹ì‹ ì€ ìì‹ ìˆê²Œ ë§í•  ìˆ˜ ìˆì„ ê²ë‹ˆë‹¤:**

> "ì €ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ˆë‹¹ 5ë§Œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
> GitHubì— ì½”ë“œê°€ ìˆê³ , ë°ëª¨ë¥¼ ë³´ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

**Good luck! ğŸš€**
